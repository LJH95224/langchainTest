import os

from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings

load_dotenv(verbose=True, override=True)
siliconflow_api_key = os.environ["SILLICONFLOW_API_KEY"]
siliconflow_base_url = os.environ["SILLICONFLOW_API_BASE"]

embeddings = OpenAIEmbeddings(
    model="Qwen/Qwen3-Embedding-4B",
    openai_api_key=siliconflow_api_key,
    openai_api_base=siliconflow_base_url,
)

from langchain_core.vectorstores import InMemoryVectorStore

texts = [
    "è¥¿æ¹–æ˜¯æ­å·è‘—åçš„æ—…æ¸¸æ™¯ç‚¹ã€‚",
    "æˆ‘æœ€å–œæ¬¢çš„æ­Œæ›²æ˜¯ã€Šæœˆäº®ä»£è¡¨æˆ‘çš„å¿ƒã€‹ã€‚",
    "æ•…å®«æ˜¯åŒ—äº¬æœ€è‘—åçš„å¤è¿¹ä¹‹ä¸€ã€‚",
    "è¿™æ˜¯ä¸€ç¯‡å…³äºåŒ—äº¬æ•…å®«å†å²çš„æ–‡æ¡£ã€‚!",
    "æˆ‘éå¸¸å–œæ¬¢å»ç”µå½±é™¢çœ‹ç”µå½±ã€‚",
    "åŒ—äº¬æ•…å®«çš„è—å“æ•°é‡è¶…è¿‡ä¸€ç™¾ä¸‡ä»¶ã€‚!",
    "è¿™åªæ˜¯ä¸€æ®µéšæœºæ–‡æœ¬ã€‚",
    "ã€Šä¸‰å›½æ¼”ä¹‰ã€‹æ˜¯ä¸­å›½å››å¤§åè‘—ä¹‹ä¸€ã€‚",
    "ç´«ç¦åŸæ˜¯æ•…å®«çš„åˆ«ç§°ï¼Œä½äºåŒ—äº¬ã€‚",
    "æ•…å®«åšç‰©é™¢æ¯å¹´æ¥å¾…æ¸¸å®¢æ•°ç™¾ä¸‡äººæ¬¡ã€‚"
]

# åˆ›å»ºæ£€ç´¢å™¨
retriever = InMemoryVectorStore.from_texts(texts, embedding= embeddings).as_retriever(
    search_kywargs={"k": 10}
)

query = "è¯·å‘Šè¯‰æˆ‘å…³äºæ•…å®«çš„æ¶ˆæ¯ï¼Ÿ"

# è·å–ç›¸å…³æ€§æ’åºçš„æ–‡æ¡£
docs = retriever.invoke(query)
for doc in docs:
    print(f"ğŸ“„  {doc.page_content}")


from langchain_community.document_transformers import LongContextReorder

# é‡æ–°æ’åºæ–‡æ¡£ï¼š
# ç›¸å…³æ€§è¾ƒä½çš„æ–‡æ¡£å°†ä½äºåˆ—è¡¨ä¸­é—´
# ç›¸å…³æ€§è¾ƒé«˜çš„æ–‡æ¡£å°†ä½äºå¼€å¤´å’Œç»“å°¾

reordering = LongContextReorder()
reordered_docs = reordering.transform_documents(docs)

# ç¡®è®¤ç›¸å…³æ€§é«˜çš„æ–‡æ¡£ä½äºå¼€å¤´å’Œç»“å°¾
for doc in reordered_docs:
    print(f"-  {doc.page_content}")

# æ•´åˆåˆ° chain é‡Œé¢å»

from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import PromptTemplate
from langchain_deepseek import ChatDeepSeek

llm = ChatDeepSeek(
    model="deepseek-chat",
    # æ¨¡å‹è‡ªç”±åº¦ï¼Œ0ä¸ºæœ€ç¡®å®šï¼ˆæ ¹æ®è¾“å…¥ç”Ÿæˆæœ€å¯èƒ½çš„è¾“å‡ºï¼‰ï¼Œ1ä¸ºæœ€éšæœºï¼ˆæ ¹æ®è¾“å…¥ç”Ÿæˆæœ€ä¸ç›¸å…³çš„è¾“å‡ºã€æ›´æœ‰åˆ›æ„ã€‘ï¼‰0.7ä¸ºä¸€ä¸ªé˜ˆå€¼
    temperature=0,
    max_tokens=None,
    timeout=None,
    # æœ€å¤§é‡è¯•æ¬¡æ•°
    max_retries=2,
    api_key=os.getenv("DEEP_SEEK_API_KEY"),
    api_base=os.getenv("DEEP_SEEK_API_BASE"),
)

prompt_template = """
    ç»™å®šä»¥ä¸‹æ–‡æœ¬:
    -----
    {context}
    -----
    è¯·å›ç­”ä»¥ä¸‹é—®é¢˜:
    {query}
    """

prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "query"]
)

chain = create_stuff_documents_chain(llm, prompt)
response = chain.invoke({"context": reordered_docs, "query": query})
print(f"\n å›å¤:{response}")