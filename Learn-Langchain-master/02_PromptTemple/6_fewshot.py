# FewShot ç¤ºä¾‹ å¤§æ¨¡å‹å­¦ä¹ ç¤ºä¾‹
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

load_dotenv()

base_url = os.getenv("BASE_URL")
model_api_key = os.getenv("MODEL_API_KEY")
model_name = os.getenv("MODEL_NAME")

llm = ChatOpenAI(
    base_url=base_url,
    api_key=model_api_key,  # ç¡®ä¿è¿™ä¸ªå¯†é’¥æ˜¯æœ‰æ•ˆçš„
    model=model_name,  # type: ignore
    temperature=0.1,   # type: ignore
    max_tokens=1000,  # type: ignore
    streaming=True
)


# ä¾‹å­
examples = [
    {"input": "2 ğŸ‘‹ 2", "output": "4"},
    {"input": "2 ğŸ‘‹ 3", "output": "6"}, 
]

# ä¾‹å­æ¨¡æ¿
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

# åŠ¨æ€ few-shot æç¤º
few_shot_prompt = FewShotChatMessagePromptTemplate(
    examples=examples,
    example_prompt=example_prompt
)

# æ ¼å¼åŒ– few-shot æç¤º
print(few_shot_prompt.invoke({}).to_messages())

# æœ€ç»ˆæç¤º
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è€å¸ˆ"),
    few_shot_prompt,
    ("human", "{input}"), 
])

chain = final_prompt | llm
resault = chain.invoke({"input": "5 ğŸ‘‹ 5"})
print(resault)