"""
åŸºäºLangGraphå®ç°çš„å…·æœ‰è®°å¿†åŠŸèƒ½çš„Agentç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphæ¡†æ¶ä¸ºLangChain Agentæ·»åŠ è®°å¿†åŠŸèƒ½ï¼Œ
ä½¿Agentèƒ½å¤Ÿè®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œæä¾›æ›´è¿è´¯çš„å›ç­”ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ä½¿ç”¨LangGraphç®¡ç†å¯¹è¯çŠ¶æ€
2. å®ç°ä¼šè¯å†å²è®°å½•ï¼ˆæŒä¹…åŒ–å­˜å‚¨åˆ°æ–‡ä»¶ï¼‰
3. æ”¯æŒæµå¼è¾“å‡ºå›ç­”
4. ä½¿ç”¨å·¥å…·å¢å¼ºAgentèƒ½åŠ›

æ³¨æ„ï¼šæ­¤å®ç°å°†å¯¹è¯å†å²ä¿å­˜åˆ°JSONæ–‡ä»¶ä¸­ï¼Œç¨‹åºé‡å¯åä»å¯è¯»å–å†å²è®°å½•ã€‚
"""

import os
import json
from dotenv import load_dotenv
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import HumanMessage, AIMessage, message_to_dict, messages_from_dict
from typing import Dict, List, Any, Tuple, Optional, TypedDict
from langgraph.graph import StateGraph, END
import time
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·å–ç¯å¢ƒå˜é‡
base_url = os.getenv("BASE_URL")  # APIåŸºç¡€URL
model_api_key = os.getenv("MODEL_API_KEY")  # APIå¯†é’¥
model_name = os.getenv("MODEL_NAME")  # æ¨¡å‹åç§°

# è‡ªå®šä¹‰æµå¼è¾“å‡ºå¤„ç†å™¨
class CustomStreamingHandler(BaseCallbackHandler):
    """
    æµå¼è¾“å‡ºå¤„ç†å™¨ï¼Œè´Ÿè´£å®æ—¶æ˜¾ç¤ºLLMç”Ÿæˆçš„æ–‡æœ¬
    
    è¿™ä¸ªå¤„ç†å™¨ä¼šæ•è·LLMç”Ÿæˆçš„æ¯ä¸ªæ–°tokenå¹¶ç«‹å³æ‰“å°å‡ºæ¥ï¼Œ
    ä»è€Œå®ç°æµç•…çš„è¾“å‡ºæ•ˆæœï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚
    """
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """
        å¤„ç†LLMç”Ÿæˆçš„æ¯ä¸ªæ–°token
        
        å‚æ•°:
            token (str): LLMç”Ÿæˆçš„å•ä¸ªtoken
            kwargs: å…¶ä»–å‚æ•°
        """
        print(token, end="", flush=True)

# åˆå§‹åŒ–LLMæ¨¡å‹ - å¯ç”¨æµå¼è¾“å‡º
llm = ChatOpenAI(
    base_url=base_url,
    api_key=model_api_key,
    model=model_name,
    temperature=0.1,  # è¾ƒä½çš„æ¸©åº¦ä½¿è¾“å‡ºæ›´åŠ ç¡®å®šæ€§
    streaming=True    # å¯ç”¨æµå¼è¾“å‡ºï¼Œä»¥ä¾¿å®æ—¶æ˜¾ç¤ºç”Ÿæˆå†…å®¹
)

# å®šä¹‰Agentå¯ç”¨çš„å·¥å…·

@tool
def search_tool(query: str) -> str:
    """
    æ¨¡æ‹Ÿæœç´¢å·¥å…· - å½“Agentéœ€è¦æŸ¥æ‰¾ä¿¡æ¯æ—¶ä½¿ç”¨
    
    å‚æ•°:
        query (str): æœç´¢æŸ¥è¯¢
    
    è¿”å›:
        str: æ¨¡æ‹Ÿçš„æœç´¢ç»“æœ
    """
    # æ¨¡æ‹Ÿå»¶è¿Ÿä»¥å±•ç¤ºçœŸå®æœç´¢åœºæ™¯
    print("\næ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯...", end="", flush=True)
    time.sleep(1)
    return f"è¿™æ˜¯å…³äº'{query}'çš„æœç´¢ç»“æœ: [æ¨¡æ‹Ÿæœç´¢ç»“æœ]"

@tool
def calculator_tool(expression: str) -> str:
    """
    è®¡ç®—å™¨å·¥å…· - å½“Agentéœ€è¦è¿›è¡Œæ•°å­¦è®¡ç®—æ—¶ä½¿ç”¨
    
    å‚æ•°:
        expression (str): æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚"2 + 2"
    
    è¿”å›:
        str: è®¡ç®—ç»“æœæˆ–é”™è¯¯ä¿¡æ¯
    """
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"

# åˆ›å»ºAgentæç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    # ç³»ç»Ÿæ¶ˆæ¯å®šä¹‰Agentçš„è¡Œä¸ºå’Œèƒ½åŠ›
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿä½¿ç”¨å·¥å…·æ¥è§£å†³é—®é¢˜ã€‚å›ç­”æ—¶ä½¿ç”¨ä¸­æ–‡ï¼Œç¡®ä¿å›å¤ç®€æ´æ¸…æ™°ã€‚"),
    # èŠå¤©å†å²è®°å½•å ä½ç¬¦ - ç”¨äºæ’å…¥å†å²æ¶ˆæ¯
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    # ç”¨æˆ·å½“å‰è¾“å…¥
    ("human", "{input}"),
    # Agentæ€è€ƒè¿‡ç¨‹å ä½ç¬¦ - ç”¨äºæ’å…¥å·¥å…·è°ƒç”¨è¿‡ç¨‹
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

# åˆ›å»ºOpenAIå‡½æ•°è°ƒç”¨Agent
agent = create_openai_functions_agent(
    llm=llm,
    tools=[search_tool, calculator_tool],
    prompt=prompt
)

# åˆ›å»ºAgentæ‰§è¡Œå™¨ - è´Ÿè´£æ‰§è¡ŒAgentçš„å†³ç­–
agent_executor = AgentExecutor(
    agent=agent,
    tools=[search_tool, calculator_tool],
    verbose=False,  # ä¸æ˜¾ç¤ºè¯¦ç»†æ‰§è¡Œæ—¥å¿—
    handle_parsing_errors=True,  # è‡ªåŠ¨å¤„ç†è§£æé”™è¯¯
    max_iterations=3  # æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
)

# --------------- LangGraphå†…å­˜å®ç° ---------------

# å®šä¹‰å›¾çŠ¶æ€ç±»å‹
class GraphState(TypedDict):
    """
    LangGraphçŠ¶æ€å®šä¹‰ - åŒ…å«ä¼šè¯å†å²å’Œå½“å‰è¾“å…¥
    
    è¿™ä¸ªç±»å®šä¹‰äº†å›¾åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä¼ é€’çš„çŠ¶æ€æ•°æ®ç»“æ„ï¼Œ
    åŒ…å«äº†ç»´æŠ¤å¯¹è¯è¿è´¯æ€§æ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ã€‚
    """
    chat_history: List[Any]  # èŠå¤©å†å²è®°å½•åˆ—è¡¨
    input: str               # å½“å‰ç”¨æˆ·è¾“å…¥

# å®šä¹‰èŠ‚ç‚¹å¤„ç†å‡½æ•°

def initialize_memory() -> GraphState:
    """
    åˆå§‹åŒ–å†…å­˜çŠ¶æ€
    
    è¿”å›:
        GraphState: åŒ…å«ç©ºèŠå¤©å†å²å’Œç©ºè¾“å…¥çš„åˆå§‹çŠ¶æ€
    """
    return {
        "chat_history": [],  # ç©ºèŠå¤©å†å²
        "input": ""          # ç©ºè¾“å…¥
    }

def process_input(state: GraphState) -> GraphState:
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥(å¯æ‰©å±•ç”¨äºè¾“å…¥é¢„å¤„ç†)
    
    å‚æ•°:
        state (GraphState): å½“å‰å›¾çŠ¶æ€
        
    è¿”å›:
        GraphState: å¤„ç†åçš„å›¾çŠ¶æ€
    """
    return state

def agent_node(state: GraphState) -> GraphState:
    """
    Agentå¤„ç†èŠ‚ç‚¹ - è°ƒç”¨Agentå¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°èŠå¤©å†å²
    
    è¿™æ˜¯LangGraphå·¥ä½œæµçš„æ ¸å¿ƒèŠ‚ç‚¹ï¼Œè´Ÿè´£ï¼š
    1. ä»çŠ¶æ€ä¸­æå–èŠå¤©å†å²å’Œç”¨æˆ·è¾“å…¥
    2. è°ƒç”¨Agentå¤„ç†è¾“å…¥
    3. æ›´æ–°èŠå¤©å†å²
    4. è¿”å›æ›´æ–°åçš„çŠ¶æ€
    
    å‚æ•°:
        state (GraphState): å½“å‰å›¾çŠ¶æ€ï¼ŒåŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·è¾“å…¥
        
    è¿”å›:
        GraphState: æ›´æ–°åçš„å›¾çŠ¶æ€ï¼ŒåŒ…å«æ–°çš„èŠå¤©å†å²
    """
    # ä»çŠ¶æ€ä¸­è·å–èŠå¤©å†å²å’Œå½“å‰è¾“å…¥
    chat_history = state["chat_history"]
    user_input = state["input"]
    
    # å‡†å¤‡Agentè°ƒç”¨çš„è¾“å…¥å‚æ•°
    agent_input = {
        "input": user_input,
        "chat_history": chat_history  # ä¼ å…¥å†å²è®°å½•ï¼Œä½¿Agentæ„ŸçŸ¥ä¸Šä¸‹æ–‡
    }
    
    # åˆ›å»ºæµå¼è¾“å‡ºå¤„ç†å™¨
    stream_handler = CustomStreamingHandler()
    
    # è°ƒç”¨Agentæ‰§è¡Œå™¨ï¼Œé™„åŠ å›è°ƒå¤„ç†æµå¼è¾“å‡º
    response = agent_executor.invoke(
        agent_input,
        config={"callbacks": [stream_handler]}  # é…ç½®æµå¼è¾“å‡ºå›è°ƒ
    )
    output = response.get("output", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚")
    
    # æ›´æ–°èŠå¤©å†å² - æ·»åŠ ç”¨æˆ·è¾“å…¥å’ŒAIå›å¤
    new_history = list(chat_history)  # åˆ›å»ºå†å²è®°å½•çš„å‰¯æœ¬
    new_history.append(HumanMessage(content=user_input))  # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    new_history.append(AIMessage(content=output))         # æ·»åŠ AIæ¶ˆæ¯
    
    # è¿”å›æ›´æ–°åçš„çŠ¶æ€
    return {
        "chat_history": new_history,  # æ›´æ–°åçš„èŠå¤©å†å²
        "input": user_input           # ä¿ç•™å½“å‰è¾“å…¥(å¯ç”¨äºæ—¥å¿—æˆ–åˆ†æ)
    }

# æŒä¹…åŒ–å­˜å‚¨ç›¸å…³å¸¸é‡å’Œå‡½æ•°
MEMORY_DIR = Path("memory")  # å†…å­˜æ–‡ä»¶å­˜å‚¨ç›®å½•
MEMORY_FILE = MEMORY_DIR / "chat_history.json"  # å†…å­˜æ–‡ä»¶è·¯å¾„

def save_chat_history(chat_history: List[Any], verbose: bool = False) -> None:
    """
    å°†èŠå¤©å†å²ä¿å­˜åˆ°JSONæ–‡ä»¶
    
    å‚æ•°:
        chat_history (List[Any]): èŠå¤©å†å²è®°å½•
        verbose (bool): æ˜¯å¦æ‰“å°ä¿å­˜æ¶ˆæ¯ï¼Œé»˜è®¤ä¸ºFalse
    """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    MEMORY_DIR.mkdir(exist_ok=True)
    
    # å°†æ¶ˆæ¯å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
    serializable_history = [message_to_dict(msg) for msg in chat_history]
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(serializable_history, f, ensure_ascii=False, indent=2)
    
    # ä»…åœ¨è¯¦ç»†æ¨¡å¼ä¸‹æ‰“å°ä¿å­˜æ¶ˆæ¯
    if verbose:
        print(f"âœ… èŠå¤©å†å²å·²ä¿å­˜åˆ°: {MEMORY_FILE}")

def load_chat_history() -> List[Any]:
    """
    ä»JSONæ–‡ä»¶åŠ è½½èŠå¤©å†å²
    
    è¿”å›:
        List[Any]: åŠ è½½çš„èŠå¤©å†å²è®°å½•ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›ç©ºåˆ—è¡¨
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not MEMORY_FILE.exists():
        print("ğŸ’¡ æœªæ‰¾åˆ°å†å²è®°å½•æ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°çš„å¯¹è¯å†å²")
        return []
    
    try:
        # ä»æ–‡ä»¶è¯»å–
        with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
            serialized_history = json.load(f)
        
        # å°†å­—å…¸è½¬æ¢å›æ¶ˆæ¯å¯¹è±¡
        history = messages_from_dict(serialized_history)
        print(f"âœ… å·²åŠ è½½ {len(history)} æ¡å†å²æ¶ˆæ¯")
        return history
    except Exception as e:
        print(f"âš ï¸ åŠ è½½å†å²è®°å½•æ—¶å‡ºé”™: {e}")
        return []

# ä½¿ç”¨LangGraphåˆ›å»ºå·¥ä½œæµ
workflow = StateGraph(GraphState)

# æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
workflow.add_node("agent", agent_node)  # æ·»åŠ Agentå¤„ç†èŠ‚ç‚¹

# é…ç½®å›¾çš„æ‰§è¡Œæµç¨‹
workflow.set_entry_point("agent")  # è®¾ç½®å…¥å£ç‚¹
workflow.add_edge("agent", END)    # è®¾ç½®å‡ºå£ç‚¹

# ç¼–è¯‘å·¥ä½œæµ
memory_graph = workflow.compile()

# --------------- ä¸»ç¨‹åº ---------------

# ä¸»ç¨‹åº - ä½¿ç”¨LangGraphå¤„ç†å¸¦æœ‰å†…å­˜çš„å¯¹è¯
if __name__ == "__main__":
    print("ğŸ¤– LangGraph å†…å­˜å¢å¼ºçš„ LangChain Agent ç¤ºä¾‹")
    print("è¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯")
    
    # ä»æ–‡ä»¶åŠ è½½å†å²å¯¹è¯è®°å½•
    loaded_history = load_chat_history()
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ - ä½¿ç”¨åŠ è½½çš„å†å²è®°å½•
    session_state = {"chat_history": loaded_history, "input": ""}
    
    # å¦‚æœæœ‰å†å²è®°å½•ï¼Œæ˜¾ç¤ºæ‘˜è¦
    if loaded_history:
        history_count = len(loaded_history) // 2  # ä¸€é—®ä¸€ç­”ä¸ºä¸€ç»„å¯¹è¯
        print(f"ğŸ“š å·²åŠ è½½ {history_count} ç»„å†å²å¯¹è¯")
        
        # æ˜¾ç¤ºæœ€åä¸€ç»„å¯¹è¯ä½œä¸ºæç¤º
        if history_count > 0:
            last_user_msg = loaded_history[-2].content if len(loaded_history) >= 2 else ""
            last_ai_msg = loaded_history[-1].content if len(loaded_history) >= 1 else ""
            print(f"\nä¸Šæ¬¡å¯¹è¯:")
            print(f"ç”¨æˆ·: {last_user_msg[:50]}{'...' if len(last_user_msg) > 50 else ''}")
            print(f"åŠ©æ‰‹: {last_ai_msg[:50]}{'...' if len(last_ai_msg) > 50 else ''}")
    
    try:
        while True:
            user_input = input("\nç”¨æˆ·: ")
            if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
                # ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶ï¼Œå¹¶æ˜¾ç¤ºä¿å­˜æ¶ˆæ¯
                save_chat_history(session_state["chat_history"], verbose=True)
                print("è°¢è°¢ä½¿ç”¨!")
                break
            
            try:
                print("\nåŠ©æ‰‹: ", end="", flush=True)
                
                # æ›´æ–°è¾“å…¥
                session_state["input"] = user_input
                
                # ä½¿ç”¨LangGraphæ‰§è¡Œå·¥ä½œæµ
                new_state = memory_graph.invoke(
                    session_state,
                    {"configurable": {"thread_id": "memory_thread"}}
                )
                
                # æ›´æ–°ä¼šè¯çŠ¶æ€
                session_state = new_state
                
                # å®šæœŸä¿å­˜èŠå¤©å†å² (é™é»˜ä¿å­˜ï¼Œä¸æ˜¾ç¤ºæ¶ˆæ¯)
                save_chat_history(session_state["chat_history"])
                
                print()  # æ¢è¡Œ
                
            except Exception as e:
                print(f"å¤„ç†å‡ºé”™: {str(e)}")
                import traceback
                print(traceback.format_exc())
    
    # ç¡®ä¿åœ¨ç¨‹åºé€€å‡ºæ—¶ä¿å­˜å†å²è®°å½•ï¼ˆå³ä½¿æ˜¯ç”±äºå¼‚å¸¸ï¼‰
    finally:
        if session_state["chat_history"]:
            save_chat_history(session_state["chat_history"], verbose=True)
            print("âš ï¸ ç¨‹åºå¼‚å¸¸é€€å‡ºï¼Œå·²ä¿å­˜èŠå¤©å†å²")