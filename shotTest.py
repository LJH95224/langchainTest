# zeroshot ä¼šå¯¼è‡´ä½è´¨é‡å›ç­” ä¸ç»™ç¤ºä¾‹ï¼Œç›´æ¥å›ç­”
import os

from dotenv import load_dotenv
from langchain_deepseek import ChatDeepSeek
from pprint import pprint
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

load_dotenv(verbose=True, override=True)
# deepseek-chat æ¨¡å‹
llm = ChatDeepSeek(
    model="deepseek-chat",
    # æ¨¡å‹è‡ªç”±åº¦ï¼Œ0ä¸ºæœ€ç¡®å®šï¼ˆæ ¹æ®è¾“å…¥ç”Ÿæˆæœ€å¯èƒ½çš„è¾“å‡ºï¼‰ï¼Œ1ä¸ºæœ€éšæœºï¼ˆæ ¹æ®è¾“å…¥ç”Ÿæˆæœ€ä¸ç›¸å…³çš„è¾“å‡ºã€æ›´æœ‰åˆ›æ„ã€‘ï¼‰0.7ä¸ºä¸€ä¸ªé˜ˆå€¼
    temperature=0,
    max_tokens=None,
    timeout=None,
    # æœ€å¤§é‡è¯•æ¬¡æ•°
    max_retries=2,
    api_key=os.getenv("DEEP_SEEK_API_KEY"),
    api_base=os.getenv("DEEP_SEEK_API_BASE"),
)
question = "ä»€ä¹ˆæ˜¯ 2 ğŸ¦ 9ï¼Ÿ"
response = llm.invoke(question)
pprint(response)

# å¢åŠ ç¤ºä¾‹

# å¢åŠ ç¤ºä¾‹ç»„
examples = [
    { "input": "2 ğŸ¦ 2", "output" : "4"},
    { "input": "2 ğŸ¦ 3", "output" : "5"},
]

# æ„é€ æç¤ºè¯æ¨¡ç‰ˆ
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

# ç»„åˆç¤ºä¾‹ä¸æç¤ºè¯
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples
)

# æ‰“å°æç¤ºè¯æ¨¡ç‰ˆ
pprint("ç»„åˆä¹‹åçš„æç¤ºè¯--------------------------")
pprint(few_shot_prompt.invoke({}).to_messages())

final_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä½ç¥å¥‡çš„æ•°å­¦å¥‡æ‰"),
    few_shot_prompt,
    ("human", "{input}"),
])

# é‡æ–°æé—®
chain = final_prompt | llm
response = chain.invoke({"input": question})
pprint("å¤„ç†åçš„ç­”æ¡ˆ--------------------------")
pprint(response)